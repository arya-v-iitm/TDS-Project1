{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import csv\n",
        "\n",
        "GITHUB_TOKEN = 'token'\n",
        "\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {GITHUB_TOKEN}',\n",
        "    'Accept': 'application/vnd.github+json',\n",
        "    'X-GitHub-Api-Version': '2022-11-28'\n",
        "}\n",
        "\n",
        "def get_users_in_chennai(min_followers=50):\n",
        "    users = []\n",
        "    page = 1\n",
        "    per_page = 30\n",
        "    while True:\n",
        "        url = f\"https://api.github.com/search/users?q=location:Chennai+followers:>{min_followers}&page={page}&per_page={per_page}\"\n",
        "        response = requests.get(url, headers=headers)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Error: {response.status_code}\")\n",
        "            break\n",
        "        data = response.json()\n",
        "\n",
        "        users.extend(data.get('items', []))\n",
        "\n",
        "        if len(users) >= data['total_count']:\n",
        "            break\n",
        "\n",
        "        page += 1\n",
        "\n",
        "    return users\n",
        "\n",
        "# get_users_in_chennai()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yU1c0Trvb853"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_company_name(company_name):\n",
        "    if not company_name:\n",
        "        return None\n",
        "    company_name = company_name.strip()\n",
        "    if company_name.startswith('@'):\n",
        "        company_name = company_name[1:]\n",
        "    company_name = company_name.upper()\n",
        "    return company_name\n",
        "\n",
        "def get_user_details(username):\n",
        "    url = f\"https://api.github.com/users/{username}\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error fetching details for {username}: {response.status_code}\")\n",
        "        return None\n",
        "    user_data = response.json()\n",
        "    user_data['company'] = clean_company_name(user_data.get('company'))\n",
        "    return user_data\n",
        "\n",
        "# get_user_details('Premalatha-success')"
      ],
      "metadata": {
        "id": "wCKzQdT2dKjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    users = get_users_in_chennai()\n",
        "    with open('users.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['login', 'name', 'company', 'location', 'email', 'hireable', 'bio',\n",
        "                      'public_repos', 'followers', 'following', 'created_at']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for user in users:\n",
        "            username = user['login']\n",
        "            print(f\"Fetching details for user: {username}\")\n",
        "            user_details = get_user_details(username)\n",
        "            if user_details:\n",
        "                writer.writerow({\n",
        "                    'login': user_details.get('login', ''),\n",
        "                    'name': user_details.get('name', ''),\n",
        "                    'company': user_details.get('company', ''),\n",
        "                    'location': user_details.get('location', ''),\n",
        "                    'email': user_details.get('email', ''),\n",
        "                    'hireable': str(user_details.get('hireable', '')).lower() if user_details.get('hireable') is not None else '',\n",
        "                    'bio': user_details.get('bio', ''),\n",
        "                    'public_repos': user_details.get('public_repos', 0),\n",
        "                    'followers': user_details.get('followers', 0),\n",
        "                    'following': user_details.get('following', 0),\n",
        "                    'created_at': user_details.get('created_at', '')\n",
        "                })\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "HfiDlsfyc-th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('users.csv')\n"
      ],
      "metadata": {
        "id": "DeMI18pQf2Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('users.csv')\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "sBs9NSpRqv-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['created_at'] = pd.to_datetime(df['created_at'])\n",
        "\n",
        "earliest_users = df.sort_values(by='created_at', ascending=True).head(5)\n",
        "\n",
        "earliest_logins = \",\".join(earliest_users['login'])\n",
        "print(earliest_logins)\n"
      ],
      "metadata": {
        "id": "hAlydmbvsa0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "\n",
        "users_df = pd.read_csv('users.csv', keep_default_na=False)\n",
        "\n",
        "def get_user_repositories(username):\n",
        "    repos = []\n",
        "    page = 1\n",
        "    per_page = 100\n",
        "    while True:\n",
        "        url = f\"https://api.github.com/users/{username}/repos?sort=updated&direction=desc&page={page}&per_page={per_page}\"\n",
        "        response = requests.get(url, headers=headers)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Error fetching repos for {username}: {response.status_code}\")\n",
        "            break\n",
        "        data = response.json()\n",
        "\n",
        "        if not data:\n",
        "            break\n",
        "\n",
        "        for repo in data:\n",
        "            repos.append({\n",
        "                'login': username,\n",
        "                'full_name': repo['full_name'],\n",
        "                'created_at': repo['created_at'],\n",
        "                'stargazers_count': repo['stargazers_count'],\n",
        "                'watchers_count': repo['watchers_count'],\n",
        "                'language': repo['language'] or '',\n",
        "                'has_projects': repo['has_projects'],\n",
        "                'has_wiki': repo['has_wiki'],\n",
        "                'license_name': repo['license']['key'] if repo['license'] else ''\n",
        "            })\n",
        "\n",
        "        if len(repos) >= 500:\n",
        "            repos = repos[:500]\n",
        "            break\n",
        "\n",
        "        page += 1\n",
        "\n",
        "    return repos\n",
        "\n",
        "def main():\n",
        "    all_repos = []\n",
        "\n",
        "    for index, user in users_df.iterrows():\n",
        "        username = user['login']\n",
        "        print(f\"Fetching repositories for user: {username}\")\n",
        "        user_repos = get_user_repositories(username)\n",
        "        all_repos.extend(user_repos)\n",
        "\n",
        "    repos_df = pd.DataFrame(all_repos)\n",
        "\n",
        "    repos_df.to_csv('repositories.csv', index=False)\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pQOClGOqyKDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('repositories.csv')"
      ],
      "metadata": {
        "id": "BQpeKHmU1MTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('repositories.csv')\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uhmDwrtf1fa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('repositories.csv')\n",
        "\n",
        "df['has_projects'] = df['has_projects'].astype(str).str.lower()\n",
        "df['has_wiki'] = df['has_wiki'].astype(str).str.lower()\n",
        "\n",
        "df.to_csv('repositories.csv', index=False)"
      ],
      "metadata": {
        "id": "ztTsQSjG1rST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repos_df = pd.read_csv('repositories.csv', keep_default_na=False)\n",
        "\n",
        "licenses = repos_df['license_name'].dropna().replace('', pd.NA)\n",
        "\n",
        "license_counts = licenses.value_counts()\n",
        "\n",
        "top_3_licenses = license_counts.head(3)\n",
        "\n",
        "top_3_license_names = \",\".join(top_3_licenses.index)\n",
        "print(top_3_license_names)\n"
      ],
      "metadata": {
        "id": "ANQ1KueI3GcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "company_counts = users_df['company'].value_counts()\n",
        "\n",
        "most_frequent_company = company_counts.index[0]\n",
        "\n",
        "most_frequent_company"
      ],
      "metadata": {
        "id": "0ehH122J3Qov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_counts = repos_df['language'].value_counts()\n",
        "\n",
        "most_frequent_language = language_counts.index[1]\n",
        "\n",
        "most_frequent_language"
      ],
      "metadata": {
        "id": "teQ6Oqtr3ZYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
        "\n",
        "recent_users = users_df[users_df['created_at'] > '2020-01-01']\n",
        "\n",
        "merged_df = pd.merge(recent_users, repos_df, on='login', how='inner')\n",
        "\n",
        "language_counts = merged_df['language'].value_counts()\n",
        "\n",
        "second_most_popular_language = language_counts.nlargest(3).index[-1]\n",
        "\n",
        "print(second_most_popular_language)"
      ],
      "metadata": {
        "id": "td-4MrtQ3sks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_stars_per_language = repos_df.groupby('language')['stargazers_count'].mean()\n",
        "\n",
        "highest_average_language = average_stars_per_language.idxmax()\n",
        "highest_average_language"
      ],
      "metadata": {
        "id": "pb0AeNb64YBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
        "\n",
        "top_5_leader_strength = users_df.sort_values(by='leader_strength', ascending=False).head(5)\n",
        "\n",
        "top_5_logins = \",\".join(top_5_leader_strength['login'])\n",
        "print(top_5_logins)"
      ],
      "metadata": {
        "id": "4aEbzy7Y4pF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "followers_repos_df = users_df[['followers', 'public_repos']]\n",
        "\n",
        "correlation = followers_repos_df['followers'].corr(followers_repos_df['public_repos'])\n",
        "\n",
        "formatted_correlation = round(correlation, 3)\n",
        "\n",
        "print(formatted_correlation)\n"
      ],
      "metadata": {
        "id": "tIUiIbFA5AHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "X = users_df['public_repos']  # Independent variable\n",
        "y = users_df['followers']      # Dependent variable\n",
        "\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "slope = model.params['public_repos']\n",
        "\n",
        "formatted_slope = round(slope, 3)\n",
        "\n",
        "print(formatted_slope)"
      ],
      "metadata": {
        "id": "eQx-l_5v5NUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repos_df = pd.read_csv('repositories.csv', keep_default_na=False)\n",
        "\n",
        "print(\"Unique values in has_projects:\", repos_df['has_projects'].unique())\n",
        "print(\"Unique values in has_wiki:\", repos_df['has_wiki'].unique())\n",
        "\n",
        "repos_df['has_projects'] = repos_df['has_projects'].astype(int)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].astype(int)\n",
        "\n",
        "print(\"Missing values in has_projects:\", repos_df['has_projects'].isna().sum())\n",
        "print(\"Missing values in has_wiki:\", repos_df['has_wiki'].isna().sum())\n",
        "\n",
        "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
        "\n",
        "formatted_correlation = round(correlation, 3)\n",
        "\n",
        "print(formatted_correlation)\n"
      ],
      "metadata": {
        "id": "hg_Rb_EM6IdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df = pd.read_csv('users.csv', keep_default_na=False)\n",
        "\n",
        "users_df['hireable'] = users_df['hireable'].replace({'True': True, 'False': False, '': False})\n",
        "\n",
        "print(\"Missing values in hireable after replacement:\", users_df['hireable'].isna().sum())\n",
        "\n",
        "users_df['hireable'] = users_df['hireable'].astype(bool)\n",
        "\n",
        "average_following_hireable = users_df[users_df['hireable']]['following'].astype(int).mean()\n",
        "average_following_non_hireable = users_df[~users_df['hireable']]['following'].astype(int).mean()\n",
        "\n",
        "average_difference = average_following_hireable - average_following_non_hireable\n",
        "\n",
        "formatted_difference = round(average_difference, 3)\n",
        "\n",
        "print(formatted_difference)\n"
      ],
      "metadata": {
        "id": "wJYnHAfl8UFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_with_bio = users_df[users_df['bio'].str.strip() != ''].copy()  # Create a copy to avoid warnings\n",
        "\n",
        "users_with_bio['bio_length'] = users_with_bio['bio'].apply(lambda x: len(x.split()))\n",
        "\n",
        "X = users_with_bio['bio_length']  # Independent variable\n",
        "y = users_with_bio['followers']    # Dependent variable\n",
        "\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "slope = model.params['bio_length']\n",
        "\n",
        "formatted_slope = round(slope, 3)\n",
        "\n",
        "print(formatted_slope)"
      ],
      "metadata": {
        "id": "DUcVC96vAUeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
        "\n",
        "repos_df['is_weekend'] = repos_df['created_at'].dt.dayofweek >= 5\n",
        "\n",
        "weekend_repos = repos_df[repos_df['is_weekend']]\n",
        "user_weekend_counts = weekend_repos['login'].value_counts().head(5)\n",
        "\n",
        "top_5_users = user_weekend_counts.index.tolist()\n",
        "\n",
        "top_5_users_string = ','.join(top_5_users)\n",
        "\n",
        "print(top_5_users_string)"
      ],
      "metadata": {
        "id": "_yY0OTgJBZ-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df = pd.read_csv('users.csv', keep_default_na=False)\n",
        "\n",
        "users_df = users_df[users_df['name'].ne('')]\n",
        "\n",
        "users_df['surname'] = users_df['name'].str.strip().str.split().str[-1]\n",
        "\n",
        "surname_counts = users_df['surname'].value_counts()\n",
        "\n",
        "max_count = surname_counts.max()\n",
        "\n",
        "most_common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n",
        "\n",
        "most_common_surnames.sort()\n",
        "\n",
        "result = ','.join(most_common_surnames)\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "1ViUg_vFCO1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df = pd.read_csv(list(uploaded.keys())[0], keep_default_na=False)"
      ],
      "metadata": {
        "id": "EGUCY7ePgqms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df['hireable'] = users_df['hireable'].replace({'True': True, 'False': False, '': False})\n",
        "users_df['hireable'] = users_df['hireable'].astype(bool)\n",
        "\n",
        "print(\"Unique values in 'hireable':\", users_df['hireable'].unique())\n",
        "\n",
        "users_df['email'] = users_df['email'].fillna('')\n",
        "\n",
        "hireable_with_email = users_df[users_df['hireable']]['email'].ne('').mean()\n",
        "non_hireable_with_email = users_df[~users_df['hireable']]['email'].ne('').mean()\n",
        "\n",
        "difference = round(hireable_with_email - non_hireable_with_email, 3)\n",
        "\n",
        "print(difference)"
      ],
      "metadata": {
        "id": "tXnEeTVUfosj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}